{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bff98f7",
   "metadata": {},
   "source": [
    "## About Dataset\n",
    "\n",
    "\n",
    "### Context:\n",
    "<p>\n",
    "The dataset is the Cleveland Heart Disease dataset taken from the UCI repository. The dataset consists of 303 individualsâ€™ data. There are 14 columns in the dataset(which have been extracted from a larger set of 75). No missing values. The classification task is to predict whether an individual is suffering from heart disease or not. (0: absence, 1: presence)\n",
    "\n",
    "original data: https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361214ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING THE BASIC NECESSARY MODULES FOR THE PROJECT\n",
    "\n",
    "import pandas as pd  # to load and manipulate the data\n",
    "import numpy as np   # to calculate the mathematical operations \n",
    "import matplotlib.pyplot as plt    # to draw graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3aef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATASET USING PANDAS\n",
    "\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\",\n",
    "                header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINTING THE FIRST 5 ROWS\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23e0f7",
   "metadata": {},
   "source": [
    "Instead of column names we are provided with column numbers. As column names makes it easier to format the data, we can replace the column numbers with the required column names\n",
    "\n",
    "- **age**\n",
    "- **sex**\n",
    "- **cp** (chest pain)\n",
    "- **restbp** (resting blood pressure in mm Hg)\n",
    "- **chol** (cholesterol in mg/dl)\n",
    "- **fbs** (fasting blood sugar)\n",
    "- **restecg** (resting electrocardiographic results)\n",
    "- **thalach** (maximum heart rate achieved)\n",
    "- **exang** (exercise induced angina)\n",
    "- **oldpeak** (ST depression)\n",
    "- **slope** (the slope of peak exercise)\n",
    "- **ca** (number of major vessels from 0 -3 colured from fluroscopy)\n",
    "- **thal** (short term of thalium heart scan)\n",
    " - **hd** (diagnosis of heart disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e286c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGING COLUMN NUMBERS TO COLUMN NAMES\n",
    "\n",
    "df.columns = ['age', 'sex', 'cp', 'restbp', \n",
    "             'chol', 'fbs', 'restecg', 'thalach', 'exang',\n",
    "             'oldpeak', 'slope', 'ca', 'thal', 'hd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771525a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDENTIFYING THE MISSING DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33499f01",
   "metadata": {},
   "source": [
    "<p>\n",
    "There are two main ways to deal with missing data:\n",
    "\n",
    "1. We can remove the rows that contain missing data from the dataset. This is relatively easy to do, but it wastes all of the other values that we\n",
    "collected. How a big of a waste this is depends on how important this missing value is for classification. For example, if we are missing a value for\n",
    "age, and age is not useful for classifying if people have heart disease or not, then it would be a shame to throw out all of someone's data just\n",
    "because we do not have their age.\n",
    "2. We can impute the values that are missing. In this context impute is just a fancy way of saying \"we can make an educated guess about about what\n",
    "the value should be\". Continuing our example where we are missing a value for age, instead of throwing out the entire row of data, we can fill the\n",
    "missing value with the average age or the median age, or use some other, more sophisticated approach, to guess at an appropriate value.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c942df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK FOR DATA TYPE FOR EACH COLUMNS\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c256f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ca'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71210fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1757c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '?' may refer to the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c8400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEALING WITH MISSING DATA\n",
    "\n",
    "len(df.loc[(df['ca'] == \"?\") | (df['thal'] == \"?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a73ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROWS HAVING MISSING DATA\n",
    "\n",
    "df.loc[(df['ca'] == \"?\") | (df['thal'] == \"?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)  # TOTAL ROWS IN A DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f28f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As only 6 rows has missing data, the rows can be deleted from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84759823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing = df.loc[(df['ca'] != \"?\") & (df['thal'] != \"?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f86719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19da272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing['ca'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e079c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_missing['thal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5565d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMATTING THE DATA: SPLIT THE DATA INTO DEPENDENT AND INDEPENDENT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f44b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_no_missing.drop(\"hd\", axis =1).copy()  \n",
    "y = df_no_missing[\"hd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55e8379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eb37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FORMATTING THE DATA: ONE - HOT ENCODING\n",
    "\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36300258",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(X, columns=['cp'], dtype=int).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4a2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=['cp', 'restecg',\n",
    "                                      'slope', 'thal'], \n",
    "                          dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265656dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbde9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_not_zero_index = y > 0 # Getting index for each non-zero value in y\n",
    "y[y_not_zero_index] = 1 # Setting non-zero values to one\n",
    "\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cb7e2b",
   "metadata": {},
   "source": [
    "## BUILDING THE CLASSIFICATION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686caccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITING THE DATA FOR TRAINING AND TESTING SET\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bd7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23adabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911fcbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dt = DecisionTreeClassifier(random_state=42)\n",
    "clf_dt = clf_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING THE TREE\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(25, 14), dpi=300)\n",
    "plot_tree(clf_dt,\n",
    "         filled=True,\n",
    "         rounded=True,\n",
    "         class_names=[\"No HD\", \"Yes HD\"],\n",
    "         feature_names=X_encoded.columns.tolist());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66566c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COST COMPLEXITY PRUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c967a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = clf_dt.cost_complexity_pruning_path(X_train, y_train) # determine values for alpha\n",
    "ccp_alphas = path.ccp_alphas # extract different values for alpha\n",
    "ccp_alphas = ccp_alphas[ :- 1] # exclude the maximum value for alpha\n",
    "\n",
    "clf_dts = [] # create an array that we will put decision trees into\n",
    "\n",
    "## now create one decision tree per value for alpha and store it in the array\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf_dt.fit(X_train, y_train)\n",
    "    clf_dts.append(clf_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a94d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = [clf_dt.score(X_train, y_train) for clf_dt in clf_dts]\n",
    "test_scores = [clf_dt.score(X_test, y_test) for clf_dt in clf_dts]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel(\"alpha\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
    "ax.plot(ccp_alphas, train_scores, marker='o', label=\"train\", drawstyle=\"steps-post\")\n",
    "ax.plot(ccp_alphas, test_scores, marker='o', label=\"test\", drawstyle=\"steps-post\")\n",
    "ax. legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9495fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "clf_dt = DecisionTreeClassifier(random_state=42, ccp_alpha=0.016)\n",
    "scores = cross_val_score(clf_dt, X_train, y_train, cv=5)\n",
    "df = pd.DataFrame(data={'tree' : range(5), 'accuracy': scores})\n",
    "df.plot(x=\"tree\", y=\"accuracy\", marker= 'o', linestyle = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28870af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array to store the results of each fold \n",
    "\n",
    "alpha_loop_values = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf_dt = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    scores = cross_val_score(clf_dt, X_train, y_train, cv=5)\n",
    "    alpha_loop_values.append([ccp_alpha, np.mean(scores), np.std(scores)])\n",
    "\n",
    "## Now we can draw a graph of the means and standard deviations of the scores\n",
    "## for each candidate value for alpha\n",
    "alpha_results = pd.DataFrame(alpha_loop_values,columns=['alpha', 'mean_accuracy', 'std'])\n",
    "\n",
    "alpha_results.plot(x='alpha',\n",
    "                y='mean_accuracy',\n",
    "                yerr='std',\n",
    "                marker='o',\n",
    "                linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccad031",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_results[(alpha_results['alpha'] > 0.014)\n",
    "&\n",
    "(alpha_results['alpha'] < 0.015)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241cd8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_ccp_alpha = alpha_results[(alpha_results['alpha'] > 0.014)\n",
    "&\n",
    "(alpha_results['alpha'] < 0.015) ]['alpha']\n",
    "\n",
    "\n",
    "\n",
    "ideal_ccp_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7942924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_ccp_alpha = float(ideal_ccp_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d609aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING THE CLASSIFICATION TREE\n",
    "\n",
    "clf_dt_pruned = DecisionTreeClassifier(random_state=42,\n",
    "                                       ccp_alpha=ideal_ccp_alpha)\n",
    "\n",
    "clf_dt_pruned = clf_dt_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c73c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 11), dpi = 250)\n",
    "plot_tree(clf_dt_pruned,\n",
    "         filled=True,\n",
    "         rounded=True,\n",
    "         class_names=[\"No HD\", \"Yes HD\"],\n",
    "         feature_names=X_encoded.columns.tolist());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30163de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
